"""
æ¨ç†å·¥å…·ç±»å’Œå‡½æ•°
"""

import os
import sys
import json
import math
import re
from abc import ABC, abstractmethod
from pathlib import Path
from tqdm import tqdm
import pandas as pd


def exp_safe(x: float) -> float:
    """å®‰å…¨åœ°å°† logprob è½¬æ¢ä¸º prob"""
    try:
        return float(math.exp(x))
    except OverflowError:
        return 0.0 if x < 0 else 1.0


def to_token_str(tok_key, tokenizer):
    """ç¡®ä¿ token key æ˜¯å­—ç¬¦ä¸²"""
    if isinstance(tok_key, int):
        return tokenizer.convert_ids_to_tokens(tok_key, skip_special_tokens=False)
    return tok_key


def build_token_level_records(vllm_request_output, top_logprobs, tokenizer):
    """æ„å»ºæ¯ä¸ª token çš„è®°å½•"""
    out = vllm_request_output.outputs[0]
    token_level = []

    # è·å–é‡‡æ ·çš„ token IDs
    sampled_token_ids = getattr(out, "token_ids", None)
    sampled_tokens_str = None
    if sampled_token_ids is not None:
        sampled_tokens_str = [
            tokenizer.convert_ids_to_tokens(tid, skip_special_tokens=False)
            for tid in sampled_token_ids
        ]

    for i, lp_dict in enumerate(out.logprobs or []):
        if not lp_dict:
            continue

        # æ”¶é›†æ‰€æœ‰ token å’Œå…¶ logprob
        pairs = []
        for tok_key, lp_obj in lp_dict.items():
            tok_str = to_token_str(tok_key, tokenizer)
            lp = getattr(lp_obj, "logprob", lp_obj)
            pairs.append((tok_str, float(lp)))

        # æŒ‰ logprob é™åºæ’åº
        pairs.sort(key=lambda x: x[1], reverse=True)
        top_pairs = pairs[:top_logprobs] if top_logprobs and top_logprobs > 0 else pairs

        # ç¡®å®šé€‰æ‹©çš„ token
        if sampled_tokens_str is not None and i < len(sampled_tokens_str):
            chosen_tok_str = sampled_tokens_str[i]
            chosen_lp = None
            for t, lp in pairs:
                if t == chosen_tok_str:
                    chosen_lp = lp
                    break
            if chosen_lp is None:
                chosen_tok_str, chosen_lp = top_pairs[0]
        else:
            chosen_tok_str, chosen_lp = top_pairs[0]

        token_level.append({
            "generate_token": chosen_tok_str,
            "logprob": float(chosen_lp),
            "prob": exp_safe(float(chosen_lp)),
            "topk": [
                {"token": t, "logprob": float(lp), "prob": exp_safe(float(lp))}
                for (t, lp) in top_pairs
            ]
        })

    return token_level


def extract_probabilities_from_token_level(token_level, all_labels):
    """ä» token level ç»“æœä¸­æå–æ ‡ç­¾æ¦‚ç‡"""
    batch_probabilities = []
    
    for i, token_record in enumerate(token_level):
        token = token_record.get("generate_token", "").strip()
        
        if token.lower() == 'label':
            # æ”¶é›† 'label' å‰é¢çš„è¿ç»­æ•°å­— tokens
            id_tokens = []
            j = i - 3
            
            while j >= 0:
                prev_token = token_level[j].get("generate_token", "").strip()
                if prev_token.isdigit():
                    id_tokens.insert(0, prev_token)
                    j -= 1
                else:
                    break
            
            id_value = "".join(id_tokens) if id_tokens else None
            
            # æŸ¥æ‰¾é¢„æµ‹çš„æ ‡ç­¾
            predicted_label_position = i + 3
            if predicted_label_position < len(token_level):
                predicted_token_data = token_level[predicted_label_position]
                predicted_token = predicted_token_data.get("generate_token", "").strip()
                
                # åˆå§‹åŒ–æ ‡ç­¾æ¦‚ç‡
                label_probs = {label: 0.0 for label in all_labels}
                
                # ä» topk ä¸­æå–æ¦‚ç‡
                if 'topk' in predicted_token_data and predicted_token_data['topk']:
                    for alt in predicted_token_data['topk']:
                        alt_token = alt['token'].strip()
                        if alt_token in all_labels:
                            label_probs[alt_token] = alt['prob']
                
                # ç¡®ä¿é¢„æµ‹çš„ token æœ‰æ¦‚ç‡
                if predicted_token in all_labels and label_probs[predicted_token] == 0.0:
                    label_probs[predicted_token] = predicted_token_data.get('prob', 0.0)
                
                result = {
                    'id': id_value,
                    'label_probs': [{'label': label, 'prob': label_probs[label]} for label in all_labels]
                }
                batch_probabilities.append(result)
    
    return batch_probabilities


def extract_probabilities_from_openai_logprobs(logprobs_data, all_labels):
    """ä»OpenAIçš„logprobsæ•°æ®ä¸­æå–æ ‡ç­¾æ¦‚ç‡"""
    batch_probabilities = []
    
    if not logprobs_data:
        return batch_probabilities
    
    for i, token_data in enumerate(logprobs_data):
        token = token_data['token'].strip()
        
        if token.lower() == 'label':
            # æŸ¥æ‰¾IDä½ç½®åœ¨i-3
            id_value = None
            if i - 3 >= 0 and i - 3 < len(logprobs_data):
                id_token = logprobs_data[i - 3]['token'].strip()
                id_value = id_token
            
            # æŸ¥æ‰¾é¢„æµ‹æ ‡ç­¾ä½ç½®åœ¨i+3
            predicted_label_position = i + 3
            if predicted_label_position < len(logprobs_data):
                predicted_token_data = logprobs_data[predicted_label_position]
                predicted_token = predicted_token_data['token'].strip()
                
                # åˆå§‹åŒ–æ ‡ç­¾æ¦‚ç‡
                label_probs = {label: 0.0 for label in all_labels}
                
                # ä»top_logprobsä¸­æå–æ¦‚ç‡
                if 'top_logprobs' in predicted_token_data and predicted_token_data['top_logprobs']:
                    for alt in predicted_token_data['top_logprobs']:
                        alt_token = alt['token'].strip()
                        if alt_token in all_labels:
                            # å°†logprobè½¬æ¢ä¸ºæ¦‚ç‡
                            alt_logprob = alt.get('logprob', float('-inf'))
                            label_probs[alt_token] = exp_safe(alt_logprob)
                
                # ç¡®ä¿é¢„æµ‹çš„tokenæœ‰æ¦‚ç‡
                if predicted_token in all_labels and label_probs[predicted_token] == 0.0:
                    # å°†logprobè½¬æ¢ä¸ºæ¦‚ç‡
                    predicted_logprob = predicted_token_data.get('logprob', float('-inf'))
                    label_probs[predicted_token] = exp_safe(predicted_logprob)
                
                result = {
                    'id': id_value,
                    'label_probs': [{'label': label, 'prob': label_probs[label]} for label in all_labels]
                }
                batch_probabilities.append(result)
    
    return batch_probabilities


class BaseRunner(ABC):
    """æ¨ç†å™¨æŠ½è±¡åŸºç±»"""
    
    def __init__(self, model_name, temperature=0.0):
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = 1024
        self.top_logprobs = 10  # ç»Ÿä¸€çš„top_logprobsè®¾ç½®
    
    @abstractmethod
    def generate(self, prompts):
        """ç”Ÿæˆæ–‡æœ¬ï¼Œè¿”å›ç»“æœåˆ—è¡¨"""
        pass
    
    def extract_labels_from_label_info(self, jsonl_file):
        """æŒ‰ä¼˜å…ˆçº§é¡ºåºæŸ¥æ‰¾ label_transform_info.json è¯»å–æ ‡ç­¾"""
        jsonl_dir = os.path.dirname(jsonl_file)
        
        # å€™é€‰è·¯å¾„åˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
        candidate_paths = []
        
        # 1. é¦–å…ˆåœ¨åŒç›®å½•ä¸‹æŸ¥æ‰¾
        candidate_paths.append(os.path.join(jsonl_dir, "label_transform_info.json"))
        
        # 2. å¦‚æœè·¯å¾„åŒ…å« 2_promptï¼Œå°è¯•æ›¿æ¢ä¸º 1_split
        if "2_prompt" in jsonl_dir:
            split_dir = jsonl_dir.replace("2_prompt", "1_split")
            candidate_paths.append(os.path.join(split_dir, "label_transform_info.json"))
        
        # æŒ‰ä¼˜å…ˆçº§å°è¯•æ¯ä¸ªå€™é€‰è·¯å¾„
        for i, label_info_file in enumerate(candidate_paths):
            if os.path.exists(label_info_file):
                try:
                    with open(label_info_file, 'r', encoding='utf-8') as f:
                        label_info = json.load(f)
                    
                    # ä» label_mapping ä¸­æå–æ‰€æœ‰æ ‡ç­¾å€¼
                    if 'label_mapping' in label_info:
                        labels = list(label_info['label_mapping'].values())
                        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ’åº
                        sorted_labels = sorted([str(label) for label in labels], key=lambda x: (not x.isdigit(), int(x) if x.isdigit() else float('inf'), x))
                        print(f"INFO: Extracted labels from label_transform_info.json (priority {i+1}): {sorted_labels}")
                        print(f"OUTPUT: Found at: {label_info_file}")
                        return sorted_labels
                    else:
                        print(f"WARNING:  No 'label_mapping' found in {label_info_file}")
                        continue
                except Exception as e:
                    print(f"WARNING:  Error reading {label_info_file}: {e}")
                    continue
        
        # 3. å¦‚æœå‰ä¸¤ä¸ªä¼˜å…ˆçº§éƒ½å¤±è´¥ï¼Œå°è¯•ä» 1_split æ•°æ®æ–‡ä»¶å¤¹ä¸­çš„CSVæ–‡ä»¶æå–æ ‡ç­¾
        if "2_prompt" in jsonl_dir:
            split_dir = jsonl_dir.replace("2_prompt", "1_split")
            try:
                # æŸ¥æ‰¾ Rseed æ–‡ä»¶å¤¹
                if os.path.exists(split_dir):
                    rseed_dirs = [d for d in os.listdir(split_dir) if d.startswith('Rseed') and os.path.isdir(os.path.join(split_dir, d))]
                    if rseed_dirs:
                        # é€‰æ‹©ç¬¬ä¸€ä¸ª Rseed æ–‡ä»¶å¤¹
                        rseed_dir = os.path.join(split_dir, rseed_dirs[0])
                        print(f"OUTPUT: Trying to extract labels from CSV files in: {rseed_dir}")
                        
                        # æŸ¥æ‰¾ y_train æˆ– y_test CSV æ–‡ä»¶
                        for csv_name in ['y_train.csv', 'y_test.csv']:
                            csv_path = os.path.join(rseed_dir, csv_name)
                            if os.path.exists(csv_path):
                                try:
                                    df = pd.read_csv(csv_path)
                                    
                                    # è·å–æ‰€æœ‰å”¯ä¸€æ ‡ç­¾å€¼
                                    if len(df.columns) > 0:
                                        # å–ç¬¬ä¸€åˆ—ä½œä¸ºæ ‡ç­¾åˆ—
                                        unique_labels = df.iloc[:, 0].unique()
                                        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ’åº
                                        sorted_labels = sorted([str(label) for label in unique_labels], key=lambda x: (not x.isdigit(), int(x) if x.isdigit() else float('inf'), x))
                                        print(f"INFO: Extracted labels from CSV file (priority 3): {sorted_labels}")
                                        print(f"OUTPUT: Found at: {csv_path}")
                                        return sorted_labels
                                except Exception as e:
                                    print(f"WARNING:  Error reading CSV file {csv_path}: {e}")
                                    continue
            except Exception as e:
                print(f"WARNING:  Error accessing 1_split directory: {e}")
        
        print(f"WARNING:  label_transform_info.json not found in any candidate locations:")
        for path in candidate_paths:
            print(f"     - {path}")
        print(f"WARNING:  Also tried extracting from CSV files in 1_split data folders")
        return None

    def extract_labels_from_jsonl(self, jsonl_file):
        all_labels = set()
        
        with open(jsonl_file, 'r', encoding='utf-8') as fin:
            for line in tqdm(fin, desc="Extracting labels from JSONL"):
                data = json.loads(line.strip())
                msgs = data["messages"]
                
                # æ–¹æ³•1: ä»user promptä¸­æå–æ ‡ç­¾é›†åˆ
                user_content = next((m.get("content", "") for m in msgs if m.get("role") == "user"), "")
                
                # æŸ¥æ‰¾ "Label set = [...]" æ¨¡å¼
                label_set_match = re.search(r'Label set = \[([^\]]+)\]', user_content)
                if label_set_match:
                    label_str = label_set_match.group(1)
                    # è§£ææ ‡ç­¾ï¼Œå¤„ç†æ•°å­—å’Œå­—ç¬¦ä¸²
                    labels = [label.strip().strip('"\'') for label in label_str.split(',')]
                    all_labels.update(labels)
                
                # æ–¹æ³•2: ä»assistant responseä¸­æå–å®é™…å‡ºç°çš„æ ‡ç­¾
                assistant_content = next((m.get("content", "") for m in msgs if m.get("role") == "assistant"), "")
                if assistant_content.strip():
                    try:
                        # å°è¯•è§£æJSONæ•°ç»„
                        response_data = json.loads(assistant_content)
                        if isinstance(response_data, list):
                            for item in response_data:
                                if isinstance(item, dict) and 'label' in item:
                                    all_labels.add(str(item['label']))
                    except (json.JSONDecodeError, ValueError):
                        # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œè·³è¿‡
                        pass
        
        # è½¬æ¢ä¸ºæ’åºåçš„åˆ—è¡¨ï¼Œæ•°å­—ä¼˜å…ˆæ’åº
        sorted_labels = sorted(list(all_labels), key=lambda x: (not x.isdigit(), int(x) if x.isdigit() else float('inf'), x))
        print(f"INFO: Extracted labels from JSONL: {sorted_labels}")
        return sorted_labels

    def process_file(self, input_jsonl, output_jsonl, origin_csv=None, max_samples=None, user_labels=None, force_overwrite=False):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œå¹¶æ ¹æ®å‚æ•°å†³å®šå¤„ç†æ–¹å¼
        if os.path.exists(output_jsonl):
            # å¦‚æœè®¾ç½®äº† force_overwriteï¼Œç›´æ¥åˆ é™¤æ–‡ä»¶
            if force_overwrite:
                try:
                    os.remove(output_jsonl)
                    print(f"ğŸ—‘ï¸  Force overwrite enabled: removed existing file {output_jsonl}")
                except Exception as exc:
                    print(f"ERROR: Failed to remove file {output_jsonl}: {exc}")
                    return False
            else:
                # å‡†å¤‡å¤šå±‚æ¡†æ¶è­¦å‘Šä¿¡æ¯
                msg_lines = [
                    "WARNING: Output file already exists.",
                    "To avoid accidental overwrite, you can choose to delete and recreate it.",
                    f"Target: {output_jsonl}",
                    "Do you want to delete this file and recreate it? (Y/N)",
                ]

                # è®¡ç®—èˆ’é€‚çš„æ¡†æ¶å®½åº¦
                inner_width = max(80, max(len(s) for s in msg_lines) + 6)
                outer_width = inner_width + 6

                # æ‰“å°åµŒå¥—æ¡†æ¶
                print("\n" + "#" * (outer_width + 4))
                print("#" + " " * (outer_width + 2) + "#")
                print("#" + "!" * (outer_width + 2) + "#")
                print("#" + " " * (outer_width + 2) + "#")

                for line in msg_lines:
                    print("#  " + "|" + line.center(inner_width) + "|  #")

                print("#" + " " * (outer_width + 2) + "#")
                print("#" + "!" * (outer_width + 2) + "#")
                print("#" + " " * (outer_width + 2) + "#")
                print("#" * (outer_width + 4) + "\n")

                # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤äº’å¼ç¯å¢ƒ
                
                interactive_mode = sys.stdin.isatty()
                
                if not interactive_mode:
                    print("Non-interactive environment detected: skipping file to avoid overwrite.")
                    return True
                
                try:
                    choice = input("Delete and recreate the existing file? [y/N]: ").strip().lower()
                except Exception:
                    print("No input available or input interrupted. Skipping file.")
                    return True

                if choice in ("y", "yes"):
                    try:
                        os.remove(output_jsonl)
                        print(f"Removed existing file: {output_jsonl}")
                    except Exception as exc:
                        print(f"Failed to remove file {output_jsonl}: {exc}")
                        return False
                else:
                    print("Operation aborted by user. Skipping file.")
                    return True
        
        # å¦‚æœç”¨æˆ·æä¾›äº†æ ‡ç­¾ï¼Œä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æ ‡ç­¾
        if user_labels:
            all_labels = user_labels
            source = "user input"
        else:
            # ä¼˜å…ˆä» label_transform_info.json æå–æ ‡ç­¾ï¼ŒJSONLä½œä¸ºå¤‡é€‰
            all_labels = self.extract_labels_from_label_info(input_jsonl)
            if all_labels:
                source = "label_transform_info.json"
            else:
                print("WARNING:  Falling back to extracting labels from JSONL content")
                try:
                    all_labels = self.extract_labels_from_jsonl(input_jsonl)
                    if not all_labels:
                        raise ValueError("No labels found in JSONL file")
                    source = "JSONL content"
                except Exception as e:
                    print(f"ERROR: Error: Could not extract labels from JSONL: {e}")
                    return False
        
        print(f"INFO: Dataset: {Path(input_jsonl).stem}, Labels from {source}: {all_labels} (total: {len(all_labels)})")
        
        # æ·»åŠ æ˜æ˜¾çš„æœ€ç»ˆæ ‡ç­¾ç¡®è®¤æ‰“å°
        print(f"TARGET: FINAL LABELS TO USE: {all_labels}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(os.path.dirname(output_jsonl), exist_ok=True)
        
        # åŠ è½½ prompts
        prompts, answers = [], []
        with open(input_jsonl, 'r', encoding='utf-8') as fin:
            for i, line in enumerate(tqdm(fin, desc="Loading prompts")):
                if max_samples and i >= max_samples:
                    break
                    
                data = json.loads(line.strip())
                msgs = data["messages"]
                
                system_prompt = next((m.get("content", "") for m in msgs if m.get("role") == "system"), "")
                user_prompt = next((m.get("content", "") for m in msgs if m.get("role") == "user"), "")
                answer = next((m.get("content", "") for m in msgs if m.get("role") == "assistant"), "")
                
                full_prompt = f"{system_prompt}\n{user_prompt}" if system_prompt else user_prompt
                prompts.append(full_prompt)
                answers.append(answer)
        
        print(f"ğŸ§  Starting inference on {len(prompts)} prompts")
        
        # è¿è¡Œæ¨ç†
        outputs = self.generate(prompts)
        
        # ä¿å­˜ç»“æœ
        with open(output_jsonl, 'w', encoding='utf-8') as fout:
            for idx, (output, gt) in enumerate(tqdm(zip(outputs, answers), desc="Saving results")):
                # æ ¹æ®ä¸åŒçš„æ¨ç†å™¨ç±»å‹å¤„ç†è¾“å‡º
                if hasattr(output, 'text') and hasattr(output, 'logprobs_data'):  # OpenAI ç»“æœå¯¹è±¡
                    generated_text = output.text
                    # ä½¿ç”¨ç»Ÿä¸€çš„OpenAI logprobsæ•°æ®å¤„ç†
                    if hasattr(self, 'logprobs_supported') and self.logprobs_supported and output.logprobs_data:
                        label_probabilities = extract_probabilities_from_openai_logprobs(output.logprobs_data, all_labels)
                    else:
                        label_probabilities = []
                elif hasattr(output, 'outputs') and hasattr(output.outputs[0], 'text'):  # vLLMè¾“å‡º
                    generated_text = output.outputs[0].text
                    # æ„å»º token level è®°å½•
                    if hasattr(self, 'logprobs_supported') and self.logprobs_supported:
                        token_level = build_token_level_records(output, getattr(self, 'top_logprobs', 10), getattr(self, 'tokenizer', None))
                        label_probabilities = extract_probabilities_from_token_level(token_level, all_labels)
                    else:
                        label_probabilities = []
                else:  # çº¯æ–‡æœ¬è¾“å‡ºï¼ˆæ™®é€šOpenAIï¼‰
                    generated_text = str(output)
                    label_probabilities = []
                
                record = {
                    "id": idx,
                    "response": generated_text,
                    "groundtruth": gt,
                    "batch_probabilities": label_probabilities,
                    "available_labels": all_labels
                }
                
                json.dump(record, fout, ensure_ascii=False)
                fout.write('\n')
        
        print(f"SUCCESS: Completed: {output_jsonl}")
        return True
